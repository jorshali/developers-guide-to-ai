{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c241b51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerry/workspace/book-repo/02-fine-tuning/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_from_disk, Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f5197fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS device.\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS device.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"MPS not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b57b3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"models/my_llm_mail_classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b92ac450",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerry/workspace/book-repo/02-fine-tuning/lib/python3.13/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe37731",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c9210e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk(\"./data/llm_mail_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e99d93f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 2,\n",
       " 'text': '<|im_start|>system\\n\\nYou are a helpful mail sorting assistant.\\nYou will classify the email summary into one of the following categories:\"India Bank\", \"India School\", \"US Bank\", \"US School\"\\nNo explanation is needed.\\nThe output should only be one of the following: \"India Bank\", \"India School\", \"US Bank\", \"US School\"\\n<|im_end|>\\n<|im_start|>user\\nCategorise: Investment update Your portfolio summary is ready Hi JENNIFER, Your investments gained 2.3% this month. Review your performance and rebalancing recommendations. Portfolio value $127,845.92 as of May 30, 2025<|im_end|>\\n<|im_start|>assistant\\n'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['test'][0]['items']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5abc20a",
   "metadata": {},
   "source": [
    "# Evaluate the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf8d1005",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [\n",
    "\t\"IN_Bank\",\n",
    "\t\"IN_School\",\n",
    "\t\"US_Bank\",\n",
    "\t\"US_School\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "995ee91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, tokenizer, data):\n",
    "    tokenized_input = tokenizer(data,return_tensors=\"pt\").to(device)\n",
    "    response = model.generate(\n",
    "        tokenized_input.input_ids,\n",
    "        attention_mask=tokenized_input.attention_mask,\n",
    "        max_new_tokens=10,\n",
    "    )\n",
    "    decoded_message = tokenizer.batch_decode(response, skip_special_tokens=True)[0]\n",
    "    decoded_category = decoded_message.split(\"Category: \")[1]\n",
    "    return decoded_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2be29131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: US_Bank, Result: IN_Bank, Index: 11\n",
      "Actual: US_Bank, Result: IN_Bank, Index: 15\n",
      "Actual: US_Bank, Result: IN_Bank, Index: 31\n",
      "Total messages: 43\n",
      "Total Error: 3\n",
      "--------------------------------------------------\n",
      "Accuracy: 93.02325581395348%\n"
     ]
    }
   ],
   "source": [
    "error_counter = 0\n",
    "index = 0\n",
    "total_messages = len(ds['test'])\n",
    "for data in ds['test']:\n",
    "    result = evaluate(model, tokenizer, data['items']['text'])\n",
    "    actual = label_names[data['items']['label']]\n",
    "    if actual != result:\n",
    "        print(f\"Actual: {actual}, Result: {result}, Index: {index}\")\n",
    "        error_counter += 1\n",
    "    index += 1\n",
    "print(f\"Total messages: {total_messages}\")\n",
    "print(f\"Total Error: {error_counter}\")\n",
    "print(\"-\"*50)\n",
    "print(f\"Accuracy: {((1-error_counter / total_messages)*100)}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "02-fine-tuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
