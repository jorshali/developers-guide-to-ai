{
  "name": "getting-started-section2",
  "version": "1.0.0",
  "description": "A simple Node server that uses the Ollama SDK to call a local Ollama LLM and stream the response",
  "author": "Jacob Orshalick",
  "main": "server.mjs",
  "scripts": {
    "start": "node server.mjs",
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "keywords": [
    "thedevelopersguidetoai",
    "node",
    "nodejs",
    "express",
    "ollama"
  ],
  "license": "ISC",
  "dependencies": {
    "cors": "^2.8.5",
    "express": "^5.1.0",
    "ollama": "^0.6.2"
  }
}
